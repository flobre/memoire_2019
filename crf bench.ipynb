{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /Users/florianbreton/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/florianbreton/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk, re, pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pprint, time\n",
    "import random\n",
    "import sklearn_crfsuite\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn_crfsuite import scorers\n",
    "from collections import Counter\n",
    "nltk.download('treebank')\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_sentence = nltk.corpus.treebank.tagged_sents(tagset='universal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NOUN'),\n",
       " ('Vinken', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('61', 'NUM'),\n",
       " ('years', 'NOUN'),\n",
       " ('old', 'ADJ'),\n",
       " (',', '.'),\n",
       " ('will', 'VERB'),\n",
       " ('join', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('board', 'NOUN'),\n",
       " ('as', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('nonexecutive', 'ADJ'),\n",
       " ('director', 'NOUN'),\n",
       " ('Nov.', 'NOUN'),\n",
       " ('29', 'NUM'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tagged Sentences  3914\n",
      "Total Number of Tagged words 100676\n",
      "Vocabulary of the Corpus 12408\n",
      "Number of Tags in the Corpus  12\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Tagged Sentences \",len(tagged_sentence))\n",
    "tagged_words=[tup for sent in tagged_sentence for tup in sent]\n",
    "print(\"Total Number of Tagged words\", len(tagged_words))\n",
    "vocab=set([word for word,tag in tagged_words])\n",
    "print(\"Vocabulary of the Corpus\",len(vocab))\n",
    "tags=set([tag for word,tag in tagged_words])\n",
    "print(\"Number of Tags in the Corpus \",len(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences in Training Data  3131\n",
      "Number of Sentences in Testing Data  783\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = train_test_split(tagged_sentence,test_size=0.2,random_state=1234)\n",
    "print(\"Number of Sentences in Training Data \",len(train_set))\n",
    "print(\"Number of Sentences in Testing Data \",len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def features(sentence,index):\n",
    "    return {\n",
    "        'is_first_capital':int(sentence[index][0].isupper()),\n",
    "        'is_first_word': int(index==0),\n",
    "        'is_last_word':int(index==len(sentence)-1),\n",
    "        'is_complete_capital': int(sentence[index].upper()==sentence[index]),\n",
    "        'prev_word':'' if index==0 else sentence[index-1],\n",
    "        'next_word':'' if index==len(sentence)-1 else sentence[index+1],\n",
    "        'is_numeric':int(sentence[index].isdigit()),\n",
    "        'is_alphanumeric': int(bool((re.match('^(?=.*[0-9]$)(?=.*[a-zA-Z])',sentence[index])))),\n",
    "        'prefix_1':sentence[index][0],\n",
    "        'prefix_2': sentence[index][:2],\n",
    "        'prefix_3':sentence[index][:3],\n",
    "        'prefix_4':sentence[index][:4],\n",
    "        'suffix_1':sentence[index][-1],\n",
    "        'suffix_2':sentence[index][-2:],\n",
    "        'suffix_3':sentence[index][-3:],\n",
    "        'suffix_4':sentence[index][-4:],\n",
    "        'contains-': 1 if '-' in sentence[index] else 0 \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def untag(sentence):\n",
    "    return [word for word,tag in sentence]\n",
    "\n",
    "\n",
    "def prepareData(tagged_sentences):\n",
    "    X,y=[],[]\n",
    "    for sentences in tagged_sentences:\n",
    "        X.append([features(untag(sentences), index) for index in range(len(sentences))])\n",
    "        y.append([tag for word,tag in sentences])\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = prepareData(train_set)\n",
    "X_test,y_test = prepareData(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DET'),\n",
       " ('competitive', 'ADJ'),\n",
       " ('rates', 'NOUN'),\n",
       " ('were', 'VERB'),\n",
       " ('generally', 'ADV'),\n",
       " ('offset', 'VERB'),\n",
       " ('*-1', 'X'),\n",
       " ('by', 'ADP'),\n",
       " ('hefty', 'ADJ'),\n",
       " ('fees', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('various', 'ADJ'),\n",
       " ('services', 'NOUN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DET',\n",
       " 'ADJ',\n",
       " 'NOUN',\n",
       " 'VERB',\n",
       " 'ADV',\n",
       " 'VERB',\n",
       " 'X',\n",
       " 'ADP',\n",
       " 'ADJ',\n",
       " 'NOUN',\n",
       " 'ADP',\n",
       " 'ADJ',\n",
       " 'NOUN',\n",
       " '.']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'is_first_capital': 1,\n",
       "  'is_first_word': 1,\n",
       "  'is_last_word': 0,\n",
       "  'is_complete_capital': 0,\n",
       "  'prev_word': '',\n",
       "  'next_word': 'competitive',\n",
       "  'is_numeric': 0,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix_1': 'T',\n",
       "  'prefix_2': 'Th',\n",
       "  'prefix_3': 'The',\n",
       "  'prefix_4': 'The',\n",
       "  'suffix_1': 'e',\n",
       "  'suffix_2': 'he',\n",
       "  'suffix_3': 'The',\n",
       "  'suffix_4': 'The',\n",
       "  'contains-': 0},\n",
       " {'is_first_capital': 0,\n",
       "  'is_first_word': 0,\n",
       "  'is_last_word': 0,\n",
       "  'is_complete_capital': 0,\n",
       "  'prev_word': 'The',\n",
       "  'next_word': 'rates',\n",
       "  'is_numeric': 0,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix_1': 'c',\n",
       "  'prefix_2': 'co',\n",
       "  'prefix_3': 'com',\n",
       "  'prefix_4': 'comp',\n",
       "  'suffix_1': 'e',\n",
       "  'suffix_2': 've',\n",
       "  'suffix_3': 'ive',\n",
       "  'suffix_4': 'tive',\n",
       "  'contains-': 0},\n",
       " {'is_first_capital': 0,\n",
       "  'is_first_word': 0,\n",
       "  'is_last_word': 0,\n",
       "  'is_complete_capital': 0,\n",
       "  'prev_word': 'competitive',\n",
       "  'next_word': 'were',\n",
       "  'is_numeric': 0,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix_1': 'r',\n",
       "  'prefix_2': 'ra',\n",
       "  'prefix_3': 'rat',\n",
       "  'prefix_4': 'rate',\n",
       "  'suffix_1': 's',\n",
       "  'suffix_2': 'es',\n",
       "  'suffix_3': 'tes',\n",
       "  'suffix_4': 'ates',\n",
       "  'contains-': 0},\n",
       " {'is_first_capital': 0,\n",
       "  'is_first_word': 0,\n",
       "  'is_last_word': 0,\n",
       "  'is_complete_capital': 0,\n",
       "  'prev_word': 'rates',\n",
       "  'next_word': 'generally',\n",
       "  'is_numeric': 0,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix_1': 'w',\n",
       "  'prefix_2': 'we',\n",
       "  'prefix_3': 'wer',\n",
       "  'prefix_4': 'were',\n",
       "  'suffix_1': 'e',\n",
       "  'suffix_2': 're',\n",
       "  'suffix_3': 'ere',\n",
       "  'suffix_4': 'were',\n",
       "  'contains-': 0},\n",
       " {'is_first_capital': 0,\n",
       "  'is_first_word': 0,\n",
       "  'is_last_word': 0,\n",
       "  'is_complete_capital': 0,\n",
       "  'prev_word': 'were',\n",
       "  'next_word': 'offset',\n",
       "  'is_numeric': 0,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix_1': 'g',\n",
       "  'prefix_2': 'ge',\n",
       "  'prefix_3': 'gen',\n",
       "  'prefix_4': 'gene',\n",
       "  'suffix_1': 'y',\n",
       "  'suffix_2': 'ly',\n",
       "  'suffix_3': 'lly',\n",
       "  'suffix_4': 'ally',\n",
       "  'contains-': 0},\n",
       " {'is_first_capital': 0,\n",
       "  'is_first_word': 0,\n",
       "  'is_last_word': 0,\n",
       "  'is_complete_capital': 0,\n",
       "  'prev_word': 'generally',\n",
       "  'next_word': '*-1',\n",
       "  'is_numeric': 0,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix_1': 'o',\n",
       "  'prefix_2': 'of',\n",
       "  'prefix_3': 'off',\n",
       "  'prefix_4': 'offs',\n",
       "  'suffix_1': 't',\n",
       "  'suffix_2': 'et',\n",
       "  'suffix_3': 'set',\n",
       "  'suffix_4': 'fset',\n",
       "  'contains-': 0},\n",
       " {'is_first_capital': 0,\n",
       "  'is_first_word': 0,\n",
       "  'is_last_word': 0,\n",
       "  'is_complete_capital': 1,\n",
       "  'prev_word': 'offset',\n",
       "  'next_word': 'by',\n",
       "  'is_numeric': 0,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix_1': '*',\n",
       "  'prefix_2': '*-',\n",
       "  'prefix_3': '*-1',\n",
       "  'prefix_4': '*-1',\n",
       "  'suffix_1': '1',\n",
       "  'suffix_2': '-1',\n",
       "  'suffix_3': '*-1',\n",
       "  'suffix_4': '*-1',\n",
       "  'contains-': 1},\n",
       " {'is_first_capital': 0,\n",
       "  'is_first_word': 0,\n",
       "  'is_last_word': 0,\n",
       "  'is_complete_capital': 0,\n",
       "  'prev_word': '*-1',\n",
       "  'next_word': 'hefty',\n",
       "  'is_numeric': 0,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix_1': 'b',\n",
       "  'prefix_2': 'by',\n",
       "  'prefix_3': 'by',\n",
       "  'prefix_4': 'by',\n",
       "  'suffix_1': 'y',\n",
       "  'suffix_2': 'by',\n",
       "  'suffix_3': 'by',\n",
       "  'suffix_4': 'by',\n",
       "  'contains-': 0},\n",
       " {'is_first_capital': 0,\n",
       "  'is_first_word': 0,\n",
       "  'is_last_word': 0,\n",
       "  'is_complete_capital': 0,\n",
       "  'prev_word': 'by',\n",
       "  'next_word': 'fees',\n",
       "  'is_numeric': 0,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix_1': 'h',\n",
       "  'prefix_2': 'he',\n",
       "  'prefix_3': 'hef',\n",
       "  'prefix_4': 'heft',\n",
       "  'suffix_1': 'y',\n",
       "  'suffix_2': 'ty',\n",
       "  'suffix_3': 'fty',\n",
       "  'suffix_4': 'efty',\n",
       "  'contains-': 0},\n",
       " {'is_first_capital': 0,\n",
       "  'is_first_word': 0,\n",
       "  'is_last_word': 0,\n",
       "  'is_complete_capital': 0,\n",
       "  'prev_word': 'hefty',\n",
       "  'next_word': 'on',\n",
       "  'is_numeric': 0,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix_1': 'f',\n",
       "  'prefix_2': 'fe',\n",
       "  'prefix_3': 'fee',\n",
       "  'prefix_4': 'fees',\n",
       "  'suffix_1': 's',\n",
       "  'suffix_2': 'es',\n",
       "  'suffix_3': 'ees',\n",
       "  'suffix_4': 'fees',\n",
       "  'contains-': 0},\n",
       " {'is_first_capital': 0,\n",
       "  'is_first_word': 0,\n",
       "  'is_last_word': 0,\n",
       "  'is_complete_capital': 0,\n",
       "  'prev_word': 'fees',\n",
       "  'next_word': 'various',\n",
       "  'is_numeric': 0,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix_1': 'o',\n",
       "  'prefix_2': 'on',\n",
       "  'prefix_3': 'on',\n",
       "  'prefix_4': 'on',\n",
       "  'suffix_1': 'n',\n",
       "  'suffix_2': 'on',\n",
       "  'suffix_3': 'on',\n",
       "  'suffix_4': 'on',\n",
       "  'contains-': 0},\n",
       " {'is_first_capital': 0,\n",
       "  'is_first_word': 0,\n",
       "  'is_last_word': 0,\n",
       "  'is_complete_capital': 0,\n",
       "  'prev_word': 'on',\n",
       "  'next_word': 'services',\n",
       "  'is_numeric': 0,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix_1': 'v',\n",
       "  'prefix_2': 'va',\n",
       "  'prefix_3': 'var',\n",
       "  'prefix_4': 'vari',\n",
       "  'suffix_1': 's',\n",
       "  'suffix_2': 'us',\n",
       "  'suffix_3': 'ous',\n",
       "  'suffix_4': 'ious',\n",
       "  'contains-': 0},\n",
       " {'is_first_capital': 0,\n",
       "  'is_first_word': 0,\n",
       "  'is_last_word': 0,\n",
       "  'is_complete_capital': 0,\n",
       "  'prev_word': 'various',\n",
       "  'next_word': '.',\n",
       "  'is_numeric': 0,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix_1': 's',\n",
       "  'prefix_2': 'se',\n",
       "  'prefix_3': 'ser',\n",
       "  'prefix_4': 'serv',\n",
       "  'suffix_1': 's',\n",
       "  'suffix_2': 'es',\n",
       "  'suffix_3': 'ces',\n",
       "  'suffix_4': 'ices',\n",
       "  'contains-': 0},\n",
       " {'is_first_capital': 0,\n",
       "  'is_first_word': 0,\n",
       "  'is_last_word': 1,\n",
       "  'is_complete_capital': 1,\n",
       "  'prev_word': 'services',\n",
       "  'next_word': '',\n",
       "  'is_numeric': 0,\n",
       "  'is_alphanumeric': 0,\n",
       "  'prefix_1': '.',\n",
       "  'prefix_2': '.',\n",
       "  'prefix_3': '.',\n",
       "  'prefix_4': '.',\n",
       "  'suffix_1': '.',\n",
       "  'suffix_2': '.',\n",
       "  'suffix_3': '.',\n",
       "  'suffix_4': '.',\n",
       "  'contains-': 0}]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.01, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.01,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9738471726864286"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred,average='weighted',labels=crf.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] c1=1e-05 ........................................................\n",
      "[CV] ............................ c1=1e-05, score=0.967, total=   5.3s\n",
      "[CV] c1=1e-05 ........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ c1=1e-05, score=0.966, total=   5.3s\n",
      "[CV] c1=1e-05 ........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   10.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ c1=1e-05, score=0.967, total=   5.5s\n",
      "[CV] c1=0.01 .........................................................\n",
      "[CV] ............................. c1=0.01, score=0.967, total=   5.4s\n",
      "[CV] c1=0.01 .........................................................\n",
      "[CV] ............................. c1=0.01, score=0.966, total=   5.5s\n",
      "[CV] c1=0.01 .........................................................\n",
      "[CV] ............................. c1=0.01, score=0.967, total=   5.6s\n",
      "[CV] c1=0.1 ..........................................................\n",
      "[CV] .............................. c1=0.1, score=0.966, total=   5.3s\n",
      "[CV] c1=0.1 ..........................................................\n",
      "[CV] .............................. c1=0.1, score=0.965, total=   5.3s\n",
      "[CV] c1=0.1 ..........................................................\n",
      "[CV] .............................. c1=0.1, score=0.966, total=   5.5s\n",
      "[CV] c1=0.5 ..........................................................\n",
      "[CV] .............................. c1=0.5, score=0.964, total=   5.3s\n",
      "[CV] c1=0.5 ..........................................................\n",
      "[CV] .............................. c1=0.5, score=0.963, total=   5.0s\n",
      "[CV] c1=0.5 ..........................................................\n",
      "[CV] .............................. c1=0.5, score=0.964, total=   5.3s\n",
      "[CV] c1=0.8 ..........................................................\n",
      "[CV] .............................. c1=0.8, score=0.963, total=   5.3s\n",
      "[CV] c1=0.8 ..........................................................\n",
      "[CV] .............................. c1=0.8, score=0.961, total=   5.3s\n",
      "[CV] c1=0.8 ..........................................................\n",
      "[CV] .............................. c1=0.8, score=0.962, total=   5.4s\n",
      "[CV] c1=1 ............................................................\n",
      "[CV] ................................ c1=1, score=0.961, total=   5.3s\n",
      "[CV] c1=1 ............................................................\n",
      "[CV] ................................ c1=1, score=0.960, total=   5.4s\n",
      "[CV] c1=1 ............................................................\n",
      "[CV] ................................ c1=1, score=0.960, total=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "                           all_possible_transitions=True, averaging=None,\n",
       "                           c=None, c1=None, c2=None,\n",
       "                           calibration_candidates=None, calibration_eta=None,\n",
       "                           calibration_max_trials=None, calibration_rate=None,\n",
       "                           calibration_samples=None, delta=None, epsilon=None,\n",
       "                           error_sensitive=None, g...,\n",
       "                           keep_tempfiles=None, linesearch=None,\n",
       "                           max_iterations=100, max_linesearch=None,\n",
       "                           min_freq=None, model_filename=None,\n",
       "                           num_memories=None, pa_type=None, period=None,\n",
       "                           trainer_cls=None, variance=None, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'c1': [1e-05, 0.01, 0.1, 0.5, 0.8, 1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "from sklearn.model_selection import learning_curve,GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import learning_curve,GridSearchCV\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "#from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "import scipy\n",
    "# define fixed parameters and parameters to search\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=crf.classes_)\n",
    "\n",
    "# search\n",
    "rs = GridSearchCV(\n",
    "    crf, {'c1': [1e-5, 0.01, 0.1, 0.5, 0.8, 1],'c1': [1e-5, 0.01, 0.1, 0.5, 0.8, 1]}, verbose=3)\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<scipy.stats._distn_infrastructure.rv_frozen object at 0x7fa0007fee48>\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(\n",
    "    crf, {'c1': [1e-5, 0.01, 0.1, 0.5, 0.8, 1],'c1': [1e-5, 0.01, 0.1, 0.5, 0.8, 1]}, verbose=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=None, c2=None, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.get_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
